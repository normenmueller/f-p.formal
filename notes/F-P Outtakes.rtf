{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf100
{\fonttbl\f0\fnil\fcharset0 .SFNSText-Light;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;}
\vieww13140\viewh14580\viewkind1
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs30 \cf0 \cb2 \expnd0\expndtw0\kerning0
F-P - Outtakes\cb1 \
\
\cb2 A silo system. On the logical level, a silo system can be understood as the entry point to a collection of silos. On the technical level, it constitutes the interface to the F-P runtime.\cb1 \
\
\cb2 packages.scala\cb1 \
\
\cb2 /** A JVM-wide, unique identifier of a silo.\cb1 \
\cb2 *\cb1 \
\cb2 * Note, the context of a host and a VMID is necessary to unambiguously\cb1 \
\cb2 * identify silos without the requirement to request consensus in a silo\cb1 \
\cb2 * landscape spread over various nodes which, for sure, would negatively\cb1 \
\cb2 * affect performance.\cb1 \
\cb2 */\cb1 \
\cb2 final case class Id(uid: Int, at: Host, in: VMID) \{\cb1 \
\
\cb2 override val toString = s"$uid:$in @ $at"\cb1 \
\
\cb2 \}\cb1 \
\
\cb2 \'85\cb1 \
\
\cb2 impl/netty/Server\cb1 \
\
\cb2 Promise the server is up and running. To fulfill this promise use `self` tied to [[silt.SiloSystem]].\cb1 \
\
\cb2 project/eclipse.scala.disabled\cb1 \
\
\cb2 import com.typesafe.sbteclipse.plugin.EclipsePlugin.EclipseKeys\cb1 \
\
\cb2 trait Eclipse \{\cb1 \
\
\cb2 lazy val eclipseSettings = Seq(\cb1 \
\cb2 EclipseKeys.eclipseOutput := Some(".target"),\cb1 \
\cb2 EclipseKeys.withSource := true\cb1 \
\cb2 )\cb1 \
\
\cb2 \}\cb1 \
\
\cb2 JFP\cb1 \
\
\cb2 \\section\{Introduction\}\cb1 \
\cb2 It is difficult to deny that data-centric programming is growing in importance.\cb1 \
\cb2 At the same time, it is no secret that the most successful systems for\cb1 \
\cb2 programming with ``big data'' have all adopted ideas from functional\cb1 \
\cb2 programming; \\ie programming with first-class functions. These functional ideas\cb1 \
\cb2 are often touted to be the key to the success of these frameworks. It is not\cb1 \
\cb2 hard to imagine why--a functional, declarative interface to data, distributed\cb1 \
\cb2 over tens to thousands of nodes, provides a more natural way for end-users and\cb1 \
\cb2 data scientists to reason about data.\cb1 \
\
\cb2 While leveraging functional programming \{\\emph\{concepts\}\}, popular\cb1 \
\cb2 implementations of the MapReduce~\\cite\{MapReduce\} model, such as Hadoop\cb1 \
\cb2 MapReduce~\\cite\{Hadoop\} for Java, have been developed without making use of\cb1 \
\cb2 functional language \{\\emph\{features\}\} such as closures. For nearly a decade, the\cb1 \
\cb2 open source interpretation of this model, Hadoop, swelled in size, remaining\cb1 \
\cb2 largely unchallenged--causing nearly all of industry to synchronize on this one\cb1 \
\cb2 implementation for most all large-scale data processing needs.\cb1 \
\
\cb2 However, in recent years, a new generation of distributed systems for\cb1 \
\cb2 large-scale data processing have suddenly cropped up, built on top of emerging\cb1 \
\cb2 functional languages like Scala~\\cite\{???\}; such systems include Apache\cb1 \
\cb2 Spark~\\cite\{Spark\}, Twitter's Scalding~\\cite\{Scalding\}, and\cb1 \
\cb2 Scoobi~\\cite\{Scoobi\}. These systems make use of functional language features in\cb1 \
\cb2 Scala in order to provide high-level, declarative APIs to end-users. Further,\cb1 \
\cb2 the benefits provided by functional programming have also won over framework\cb1 \
\cb2 designers--some have noticed that immutability, and data transformation\cb1 \
\cb2 via higher-order functions makes it much easier, by design, to tackle concerns\cb1 \
\cb2 central to distributed systems such as concurrency.\cb1 \
\
\cb2 This sudden proliferation of new frameworks for distributed data-centric\cb1 \
\cb2 programming, concurrent with the sudden growth in popularity of an emerging\cb1 \
\cb2 programming language, begs the question--has it been our programming languages\cb1 \
\cb2 that have limited us? Could it be that the primitives we build our systems upon\cb1 \
\cb2 are too low-level, causing us to struggle to reinvent the same tricky wheel over\cb1 \
\cb2 and over again? As these large-scale data processing applications continue to\cb1 \
\cb2 grow in importance, what can we as language designers~\\todo\{"language\cb1 \
\cb2 designers"?\}\\comment\{sounds like we want to adapt/ modify/ improve one of those\cb1 \
\cb2 previously mentioned "emerging programming languages"\} do to make it easier for\cb1 \
\cb2 more of these frameworks to rise?\cb1 \
\
\cb2 This paper presents a new programming model\\footnote\{An abstraction of the\cb1 \
\cb2 underlying computer system that allows for the expression of both algorithms and\cb1 \
\cb2 data structures.\} called the \{\\FP\} model which has been designed to be a more\cb1 \
\cb2 principled substrate (or middleware) upon which to build data-centric\cb1 \
\cb2 distributed systems. It can be viewed as a generalization of the programming\cb1 \
\cb2 models classified by MapReduce/Apache Spark--though it is not limited to, as we\cb1 \
\cb2 will later show.\cb1 \
\
\cb2 %% Intension:\cb1 \
\cb2 %% In the subsequent two paragraphs, without going into details, I\cb1 \
\cb2 %% want to clarify what we adopt and, on the other hand, to differentiate our\cb1 \
\cb2 %% approach from those other programming models.\cb1 \
\
\cb2 Traditional parallelism brings data to compute, whereas the aforementioned class\cb1 \
\cb2 of programming models does the opposite--it brings compute to data. We adopt\cb1 \
\cb2 this feature, known as \{\\emph\{data locality\}\}, but elevate communication and\cb1 \
\cb2 expressiveness via our unique combination of a framework for object-oriented\cb1 \
\cb2 pickler combinators~\\cite\{Pickling\} and a type-based foundation for\cb1 \
\cb2 closures~\\cite\{Spores\} with a novel concept of statically typed, yet\cb1 \
\cb2 flexible\\todo\{Unlike RDD\}\\comment\{Here I'm trying to hint the reader to the fact\cb1 \
\cb2 that the concept of silos is more flexible than RDDs in terms of operations on\cb1 \
\cb2 the "silo'd" data\}, monadic silos\\comment\{How is our approach more flexible rsp.\cb1 \
\cb2 more general than those other programming models? Pickling and Spores are one\cb1 \
\cb2 thing, but how are silos more flexible than RDD[T]?\}. These stationary,\cb1 \
\cb2 immutable data structures can be remotely referenced. Transformations are\cb1 \
\cb2 executed via the application of those closures, which are guaranteed to be\cb1 \
\cb2 serializable. Performance and simplicity of persisting runtime objects are\cb1 \
\cb2 ensured by the pickler framework.\cb1 \
\
\cb2 This innovation enables two important benefits for distributed system builders:\cb1 \
\cb2 (a) since all computations are functional transformations on type-flexible\cb1 \
\cb2 monadic silos\\footnote\{In contrast to Apache Spark's RDDs~\\cite\{RDD\}, those\cb1 \
\cb2 statically typed, first order type constructors, give maximum freedom for user\cb1 \
\cb2 defined operations on the siloed data.\},\\todo\{RDD[T]'s map, flatMap give the\cb1 \
\cb2 same degree of freedom?\}\\comment\{If we do not differenciate our approach here,\cb1 \
\cb2 item (a) is given by the adoptation, \\ie does not belong to our innovation\}\cb1 \
\cb2 fault-tolerance is made simple by design, and (b) communication is made\cb1 \
\cb2 well-typed by design, a common pain point for builders of distributed systems.\cb1 \
\
\cb2 Said another way, the \{\\FP\} model attempts to more naturally model the paradigm\cb1 \
\cb2 of data-centric programming by extending monadic programming to the network.\cb1 \
\
\cb2 \\fixme\{On this note, one might observe that the function passing model can\cb1 \
\cb2 actually be interpreted as somewhat of a dual to the actor model;\\footnote\{There\cb1 \
\cb2 are many variations and interpretations of the actor model; in saying our model\cb1 \
\cb2 is somewhat of a dual, we simply mean to highlight that programmers need not\cb1 \
\cb2 focus on programming with typically stationary message handlers. Instead, our\cb1 \
\cb2 model focuses on a monadic interface for programming with data (and sending\cb1 \
\cb2 functions instead).\} rather than keeping functionality stationary and sending\cb1 \
\cb2 data, in our model, we keep data stationary and send functionality to the data.\}}