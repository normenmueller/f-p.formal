\documentclass{article}
\usepackage[utf8]{inputenc}

\title{F-P | Introduction}

\begin{document}

\maketitle

\section{Introduction}

It is difficult to deny that data-centric programming is growing in importance.
At the same time, it is no secret that the most successful systems for
programming with ``big data'' have all adopted ideas from functional
programming; i.e., programming with first-class functions. These functional ideas
are often touted to be the key to the success of these frameworks. It is not
hard to imagine why--a functional, declarative interface to data, distributed
over tens to thousands of nodes, provides a more natural way for end-users and
data scientists to reason about data.

While leveraging functional programming {\em concepts}, popular implementations
of Google's MapReduce~\cite{MapReduce} model, such as Apache Hadoop's
MapReduce Framework~\cite{Hadoop} for Java, have been developed without making use of
functional language {\em features} such as closures. For nearly a decade, the
Apache Hadoop open source interpretation of this model swelled in size,
remaining largely unchallenged--causing nearly all of industry to synchronize on
this one implementation for most all large-scale data processing needs.

However, in recent years, a new generation of distributed systems for
large-scale data processing have suddenly cropped up, built on top of emerging
functional languages like Scala~\cite{ScalaBook}; such systems include Apache
Spark~\cite{Spark}, Twitter's Scalding~\cite{Scalding}, and
Scoobi~\cite{Scoobi}. These systems make use of functional language features in
Scala in order to provide high-level, declarative APIs to end-users. Further,
the benefits provided by functional programming have also won over framework
designers as well--some have noticed that immutability, and data transformation
via higher-order functions makes it much easier, by design, to tackle concerns
central to distributed systems such as concurrency.

%% What's the problem?
While widely adopted in practice, the aforementioned programming systems are not without important issues. On the one hand, their programming interfaces do not prevent common usage errors, such as unsafe closure serialization; as a result, the complexities of distribution may trickle even to end users, who are increasingly non-expert users. On the other hand, the foundations of their programming models remain largely unclear, in particular, foundations of core aspects such as fault tolerance, a critical aspect for distributed operation on a large scale.

%% What the paper does
%%% Programming model
This paper introduces a new programming model which embraces the principle of stationary data and mobile functions (``compute to data''). It can be viewed as a generalization of the programming models classified by Google's MapReduce/Apache Spark. Our programming model adopts the concept of {\em lineage} which is used by the aforementioned systems to provide fault tolerance. Lineage-based fault tolerance is facilitated by the core computational principle of transformations on immutable, stationary data.

%%% Unique combination
The programming model is based on functional abstractions for lineage-based distributed computation. In order to prevent common usage errors, the model builds upon two previous veins of work--type-safe serialization based on functional pickler combinators~\cite{Kennedy,Elsman,Pickling,AliceML}, and serializable closures~\cite{CloudHaskell,Spores}. We believe this unique combination of functional programming techniques provides a more principled substrate upon which to build data-centric, distributed systems.

%%% Formalization
Moreover, we provide a complete formalization of the programming model in order to study the foundations of lineage-based distributed computation. In particular, we develop a theory of safe, mobile lineages based on a subject reduction theorem for a typed core language. Thus, the formal model may serve as a basis for further developments of the theory of data-centric distributed programming, including aspects such as fault tolerance.

%% Contributions

This paper makes the following contributions:
\begin{itemize}
  \item A new data-centric programming model for functional processing of distributed data which makes important concerns like fault tolerance simpler by design. The main computational principle is based on the idea of sending safe, guaranteed serializable functions to stationary data. Using standard monadic operations, our model enables creating immutable directed acyclic graphs (DAG) of computations, supporting decentralized distributed computations. Deferred evaluation enables important optimizations (operation fusion~\cite{FlumeJava}) while keeping programs simple to reason about.

  \item A formalization of lineage-based distributed computation based on a small-step operational semantics. Our formalization extends previous theories of serializable closures to {\em serializable lineages}. The technical development enabling this extension combines and generalizes (a) serializable types, (b) ``static'' closures, and (c) lineages.

  \item A proof of a subject reduction theorem for a typed, distributed core language based on lineages.

  \item A proof establishing the preservation of lineage mobility by reduction for a typed, distributed core language. This property provides a foundation for lineage-based fault tolerance.
  
  fact that reduction preserves the mobility of lineages. This property provides a foundation for lineage-based fault tolerance.



This paper presents a principled approach to
lineage-based fault recovery in a {\em purely functional} setting--to our
knowledge a novelty in the PL literature.
\end{itemize}


\end{document}
